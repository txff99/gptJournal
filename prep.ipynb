{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def parse_dialogue_file(file_path: str, numlines: int = None):\n",
    "    parsed_dialogues = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for i, line in enumerate(file):    \n",
    "            if numlines is not None and i == numlines:  break\n",
    "            turns = line.strip().split('__eou__')\n",
    "            turns = [turn.strip() for turn in turns if turn.strip()]\n",
    "            parsed_dialogues.append(turns)\n",
    "\n",
    "    return parsed_dialogues\n",
    "\n",
    "def make_chunks(dialogues, chunk_size=8, padding=2):\n",
    "    all_sentences = [' ']*padding + [sentence for line in dialogues for sentence in line] + [' ']*padding\n",
    "    return [\n",
    "        ' '.join(all_sentences[i - padding:i + chunk_size + padding])\n",
    "        for i in range(padding, len(all_sentences)+padding, chunk_size)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lawlet/miniconda3/envs/lchain/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/lawlet/miniconda3/envs/lchain/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#  encode all data\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embed_model = SentenceTransformer(\"sentence-transformers/msmarco-MiniLM-L12-cos-v5\", trust_remote_code=True)\n",
    "embed_model_dims = embed_model.get_sentence_embedding_dimension()\n",
    "\n",
    "def encode_chunks(chunks):\n",
    "    embeddings = embed_model.encode(chunks)\n",
    "    return embeddings.tolist()\n",
    "\n",
    "file_path = 'dialogues_train.txt'\n",
    "parsed = parse_dialogue_file(file_path)\n",
    "chunks = make_chunks(parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1093/10897 [01:37<2:33:01,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2183/10897 [03:12<1:56:44,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3270/10897 [04:56<2:05:56,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 2 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4360/10897 [06:41<1:27:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 3 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5449/10897 [08:01<1:13:15,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 4 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 6538/10897 [09:16<1:03:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 5 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 7627/10897 [10:51<44:06,  1.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 6 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 8716/10897 [12:28<33:34,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 7 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 9804/10897 [14:04<17:31,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 8 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 10895/10897 [15:45<00:01,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 9 upload to server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10897/10897 [15:45<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload the remaining...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# push data to db\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), 'third_party', 'tidb-vector-python')))\n",
    "\n",
    "from tidb_vector.integrations import TiDBVectorClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the connection string from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "vector_store = TiDBVectorClient(\n",
    "   # The table which will store the vector data.\n",
    "   table_name='embedded_documents',\n",
    "   # The connection string to the TiDB cluster.\n",
    "   connection_string=os.environ.get('TIDB_DATABASE_URL'),\n",
    "   # The dimension of the vector generated by the embedding model.\n",
    "   vector_dimension=embed_model_dims,\n",
    "   # Determine whether to recreate the table if it already exists.\n",
    "#    drop_existing_table=True,\n",
    ")\n",
    "\n",
    "count = 0\n",
    "for i,chunk in tqdm(enumerate(chunks),total=len(chunks)):\n",
    "    idx = i % (len(chunks)//10)\n",
    "    data.append({\"embedding\": encode_chunks(chunks=chunk), \"text\": chunk})\n",
    "    \n",
    "    if idx == 0 and i != 0:\n",
    "        vector_store.insert(\n",
    "            embeddings=[d[\"embedding\"] for d in data],\n",
    "            texts=[d[\"text\"] for d in data],\n",
    "        )\n",
    "        print(f\"chunk {count} upload to server\")\n",
    "        data = []\n",
    "        count += 1\n",
    "print(\"upload the remaining...\")\n",
    "vector_store.insert(\n",
    "   embeddings=[d[\"embedding\"] for d in data],\n",
    "   texts=[d[\"text\"] for d in data],\n",
    ")\n",
    "print(\"done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "respond in 0.20792269706726074\n",
      "Search result (\"Jim, do you remeber the time i ask you out for beer?\"):\n",
      "- text: \"What's wrong ? There's a girl in my company that I really like but I always get shy when she is around . I see ! Do you want to ask her out ? Sure , but how ? You can ask her out for drinks after work . But for what reasons ? She doesn't even know who I am . Then you've got a lot of work to do . You need to get her to notice you first . Easier said than done . You can start by meeting her at the bus stop and saying ' hello ' to her . But I always get tongue-tied when I see her . That's something you need to overcome . Men should make the first move as most girls prefer being chased . I see . I'll try .\", distance: 0.479329700310144\n",
      "- text: \"Sure , but how ? You can ask her out for drink after work . But for what reasons ? She doesn't even know who I am . Then you've got a lot of homework to do . You need to get her notice first . Easier said than done . You can start by meeting her at the bus stop and saying hello to her . But I always get tongue-tied when I see her . That's something you need to overcome . Men should make the first move as most of girls prefer being chased . I see . I'll try . Good luck . It's too hot to read . We'd better go out for a walk .\", distance: 0.48445212655685543\n",
      "- text: \"what's wrong ? there's a girl in my company that I really like but I always get shy when she is around . I see ! Do you want to ask her out ? sure , but how ? you can ask her out for drink after work . but for what reasons ? She doesn't even know who I am . then you've got a lot of homework to do . You need to get her notice first . easier said than done . you can start by meeting her at the bus stop and saying hello to her . but I always get tongue-tied when I see her . that's something you need to overcome . Men should make the first move as most of girls prefer being chased . I see . I'll try .\", distance: 0.4897473721943333\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# push data to db\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), 'third_party', 'tidb-vector-python')))\n",
    "\n",
    "from tidb_vector.integrations import TiDBVectorClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the connection string from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "vector_store = TiDBVectorClient(\n",
    "   # The table which will store the vector data.\n",
    "   table_name='embedded_documents',\n",
    "   # The connection string to the TiDB cluster.\n",
    "   connection_string=os.environ.get('TIDB_DATABASE_URL'),\n",
    "   # The dimension of the vector generated by the embedding model.\n",
    "   vector_dimension=embed_model_dims,\n",
    "   # Determine whether to recreate the table if it already exists.\n",
    "#    drop_existing_table=True,\n",
    ")\n",
    "\n",
    "def print_result(query, result):\n",
    "   print(f\"Search result (\\\"{query}\\\"):\")\n",
    "   for r in result:\n",
    "      print(f\"- text: \\\"{r.document}\\\", distance: {r.distance}\")\n",
    "\n",
    "query = \"Say , Jim , how about going for a few beers after dinner?\"\n",
    "query_embedding = encode_chunks(query)\n",
    "now = time.time()\n",
    "search_result = vector_store.query(query_embedding, k=3)\n",
    "print(f\"respond in {time.time()-now}\")\n",
    "print_result(query, search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
